# =====================================================
# Pegos Dataset Cleaning Script ðŸ§¹
# =====================================================
import os
import pandas as pd
from huggingface_hub import HfApi, hf_hub_download

HF_TOKEN = os.getenv("HF_TOKEN")
HF_DATASET_REPO = os.getenv("HF_DATASET_REPO")

api = HfApi(token=HF_TOKEN)

print("ðŸ“¥ Hugging Face'ten merged dataset indiriliyor...")
path = hf_hub_download(
    repo_id=HF_DATASET_REPO,
    filename="data/latest_merged.csv",
    repo_type="dataset",
    token=HF_TOKEN,
)

df = pd.read_csv(path)
print(f"âœ… Veri yÃ¼klendi: {df.shape[0]} satÄ±r, {df.shape[1]} sÃ¼tun")

# -----------------------------
# 1ï¸âƒ£ Ä°lgili sÃ¼tunlarÄ± seÃ§
# -----------------------------
columns_needed = [
    "tweet",
    "comment",
    "retweet",
    "like",
    "see_count",
    "time",
    "open",
    "close",
    "diff",
]
df = df[[c for c in columns_needed if c in df.columns]]

# SÃ¼tun isimlerini TÃ¼rkÃ§e'ye Ã§evir
df.rename(columns={
    "open": "AÃ§Ä±lÄ±ÅŸ FiyatÄ± (USD)",
    "close": "KapanÄ±ÅŸ FiyatÄ± (USD)",
    "diff": "Fark (USD)"
}, inplace=True)

# -----------------------------
# 2ï¸âƒ£ Yinelenen verileri kaldÄ±r
# -----------------------------
before = len(df)
df.drop_duplicates(subset=["tweet", "time"], inplace=True)
after = len(df)
print(f"ðŸ§© Yinelenen veriler kaldÄ±rÄ±ldÄ±: {before - after} satÄ±r silindi.")

# -----------------------------
# 3ï¸âƒ£ Eksik deÄŸerleri temizle
# -----------------------------
missing_before = df.isnull().sum().sum()
df.dropna(subset=["tweet", "AÃ§Ä±lÄ±ÅŸ FiyatÄ± (USD)", "KapanÄ±ÅŸ FiyatÄ± (USD)"], inplace=True)
missing_after = df.isnull().sum().sum()
print(f"ðŸš¿ Eksik deÄŸer temizliÄŸi tamamlandÄ±. {missing_before - missing_after} boÅŸ alan temizlendi.")

# -----------------------------
# 4ï¸âƒ£ AykÄ±rÄ± deÄŸer analizi (Z-score)
# -----------------------------
import numpy as np
for col in ["comment", "retweet", "like", "see_count", "Fark (USD)"]:
    if col in df.columns:
        z = np.abs((df[col] - df[col].mean()) / df[col].std())
        outliers = (z > 3).sum()
        df = df[z <= 3]
        print(f"âš ï¸ {col} sÃ¼tununda {outliers} aykÄ±rÄ± deÄŸer Ã§Ä±karÄ±ldÄ±.")

# -----------------------------
# 5ï¸âƒ£ Tarih formatÄ± dÃ¼zelt
# -----------------------------
df["time"] = pd.to_datetime(df["time"], errors="coerce")
df.dropna(subset=["time"], inplace=True)

# -----------------------------
# 6ï¸âƒ£ SonuÃ§larÄ± kaydet
# -----------------------------
output_path = "/tmp/pegos_cleaned_dataset.csv"
df.to_csv(output_path, index=False)
print(f"ðŸ’¾ TemizlenmiÅŸ veri kaydedildi: {output_path} ({len(df)} satÄ±r)")

# Hugging Face'e yÃ¼kle
api.upload_file(
    path_or_fileobj=output_path,
    path_in_repo="data/latest_cleaned.csv",
    repo_id=HF_DATASET_REPO,
    repo_type="dataset",
)
print("ðŸš€ Hugging Face'e yÃ¼kleme tamamlandÄ±: data/latest_cleaned.csv")
