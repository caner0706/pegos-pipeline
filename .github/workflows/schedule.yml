name: Pegos Live Data Fetch & Upload

on:
  schedule:
    - cron: "0 6,10,14,18 * * *"   # UTC -> TR: 09:00, 13:00, 17:00, 21:00
  workflow_dispatch:

jobs:
  fetch_and_upload:
    runs-on: ubuntu-latest
    timeout-minutes: 35

    env:
      HF_TOKEN: ${{ secrets.HF_TOKEN }}
      HF_DATASET_REPO: ${{ secrets.HF_DATASET_REPO }}
      TWITTER_USER: ${{ secrets.TWITTER_USER }}
      TWITTER_PASS: ${{ secrets.TWITTER_PASS }}
      KEEP_LAST: ${{ secrets.KEEP_LAST }}

    steps:
      - name: üì¶ Checkout repository
        uses: actions/checkout@v4

      - name: üêç Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: üß© Install Chrome & dependencies
        run: |
          set -e
          sudo apt-get update
          sudo apt-get install -y wget gnupg
          wget -q -O - https://dl.google.com/linux/linux_signing_key.pub | sudo apt-key add -
          echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" | sudo tee /etc/apt/sources.list.d/google-chrome.list
          sudo apt-get update
          sudo apt-get install -y google-chrome-stable
          python -m pip install --upgrade pip
          pip install jupyter selenium webdriver-manager beautifulsoup4 pandas huggingface_hub requests

      - name: üîç Debug environment & Hugging Face auth
        run: |
          set -e
          echo "=== DEBUG ENV ==="
          echo "HF_DATASET_REPO=${HF_DATASET_REPO}"
          echo "TWITTER_USER=${TWITTER_USER}"
          echo "KEEP_LAST=${KEEP_LAST}"
          echo "HF_TOKEN length: ${#HF_TOKEN}"
          echo "huggingface_hub version:"
          python -m pip show huggingface_hub || true
          echo "HF whoami check:"
          python - <<'PY'
import os
from huggingface_hub import HfApi
try:
    api = HfApi(token=os.getenv("HF_TOKEN"))
    who = api.whoami()
    print("‚úÖ Logged in as:", who.get("name"))
except Exception as e:
    print("‚ùå HF login check failed:", e)
PY
          echo "=================="

      - name: üöÄ Run Pegos data scraper (data.ipynb)
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
          HF_DATASET_REPO: ${{ secrets.HF_DATASET_REPO }}
          TWITTER_USER: ${{ secrets.TWITTER_USER }}
          TWITTER_PASS: ${{ secrets.TWITTER_PASS }}
          KEEP_LAST: ${{ secrets.KEEP_LAST }}
        run: |
          set -e
          echo "üöÄ Starting Pegos Twitter Scraper..."
          jupyter nbconvert --to notebook --execute data.ipynb --output output.ipynb --ExecutePreprocessor.timeout=1800
          echo "‚úÖ Notebook executed successfully"

      - name: üßæ Debug Hugging Face dataset contents
        if: always()
        run: |
          echo "üîç Listing files in Hugging Face dataset..."
          python - <<'PY'
import os
from huggingface_hub import HfApi
api = HfApi(token=os.getenv("HF_TOKEN"))
repo = os.getenv("HF_DATASET_REPO")
try:
    files = api.list_repo_files(repo_id=repo, repo_type="dataset")
    if files:
        print("üìÇ Files in dataset:")
        for f in files:
            print(" -", f)
    else:
        print("‚ö†Ô∏è No files found in dataset.")
except Exception as e:
    print("‚ùå Error listing files:", e)
PY

      - name: üìò Post-run log summary
        if: always()
        run: |
          echo "üìò Notebook execution finished."
          echo "üîç Checking output presence:"
          ls -lah | grep output || echo "‚ö†Ô∏è output.ipynb not found"
