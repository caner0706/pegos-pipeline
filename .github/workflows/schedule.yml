name: Scheduled Data Fetch

on:
  schedule:
    - cron: '0 6,10,14,18 * * *'   # UTC -> T√ºrkiye saatiyle 09:00, 13:00, 17:00, 21:00
  workflow_dispatch:

jobs:
  fetch_and_upload:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Install requirements
        run: |
          pip install -r requirements.txt

      # üîç DEBUG STEP ‚Äî Env kontrol√º
      - name: Debug environment variables
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
          HF_DATASET_REPO: ${{ secrets.HF_DATASET_REPO }}
          TWITTER_USER: ${{ secrets.TWITTER_USER }}
          KEEP_LAST: ${{ secrets.KEEP_LAST }}
        run: |
          echo "=== DEBUG ENVIRONMENT VARIABLES ==="
          echo "HF_DATASET_REPO=$HF_DATASET_REPO"
          echo "TWITTER_USER=$TWITTER_USER"
          echo "KEEP_LAST=$KEEP_LAST"
          echo "Token length: ${#HF_TOKEN}"
          python - <<'EOF'
import os
from huggingface_hub import HfApi
try:
    api = HfApi(token=os.getenv("HF_TOKEN"))
    user = api.whoami()
    print(f"‚úÖ HF token valid. Logged in as: {user['name']}")
except Exception as e:
    print("‚ùå HF token invalid or cannot connect:", e)
EOF
          echo "===================================="

      - name: Execute notebook (√ºretir: data/output.csv)
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
          HF_DATASET_REPO: ${{ secrets.HF_DATASET_REPO }}
          TWITTER_USER: ${{ secrets.TWITTER_USER }}
          TWITTER_PASS: ${{ secrets.TWITTER_PASS }}
          KEEP_LAST: ${{ secrets.KEEP_LAST }}
        run: |
          jupyter nbconvert --to notebook --execute data.ipynb --output output.ipynb

      - name: Upload to Hugging Face Dataset
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
          HF_DATASET_REPO: ${{ secrets.HF_DATASET_REPO }}
        run: |
          python upload_to_hf.py
