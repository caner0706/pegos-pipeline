# =====================================================
# Pegos Dataset Builder (Today-only, Stable Schema, BTC Fallback)
# =====================================================
import os
import time
import pandas as pd
import requests
from datetime import datetime, timezone, timedelta
from huggingface_hub import hf_hub_download, upload_file

HF_TOKEN = os.getenv("HF_TOKEN")
HF_DATASET_REPO = os.getenv("HF_DATASET_REPO")

TODAY = datetime.utcnow().strftime("%Y-%m-%d")
print(f"ğŸ“‚ GÃ¼nlÃ¼k klasÃ¶r: {TODAY}")

# 1) BugÃ¼nkÃ¼ final dosyasÄ± (varsa)
existing_df = pd.DataFrame()
try:
    p = hf_hub_download(
        repo_id=HF_DATASET_REPO,
        filename=f"data/{TODAY}/pegos_final_dataset.csv",
        repo_type="dataset",
        token=HF_TOKEN
    )
    existing_df = pd.read_csv(p, encoding="utf-8")
    print(f"ğŸ” Mevcut veri bulundu: {len(existing_df)} satÄ±r")
except Exception:
    print("â„¹ï¸ Mevcut gÃ¼nlÃ¼k dataset yok, yeni oluÅŸturulacak.")

# 2) Yeni tweet CSV (Ã¶nce latest, yoksa arÅŸiv)
new_df = pd.DataFrame()
for name in [f"data/{TODAY}/latest.csv", f"data/{TODAY}/blockchain_tweets_{TODAY}.csv"]:
    try:
        p = hf_hub_download(repo_id=HF_DATASET_REPO, filename=name, repo_type="dataset", token=HF_TOKEN)
        new_df = pd.read_csv(p, encoding="utf-8")
        print(f"âœ… Veri bulundu: {name}")
        break
    except Exception:
        continue

if new_df.empty:
    print("âš ï¸ Yeni tweet verisi bulunamadÄ± / boÅŸ.")
    new_df = pd.DataFrame(columns=["tweet","comment","retweet","like","see_count","time"])

# 3) Normalize â€” time parse et, AMA tÃ¼m satÄ±rlarÄ± bugÃ¼nÃ¼n dosyasÄ±nda bugÃ¼ne yaz
if "time" in new_df.columns:
    new_df["time"] = pd.to_datetime(new_df["time"], errors="coerce", utc=True)
else:
    new_df["time"] = pd.NaT

# ÅEMAYI SABÄ°TLE (eÄŸitim ÅŸemasÄ±na uygun + target boÅŸ)
for c in ["tweet","comment","retweet","like","see_count","time"]:
    if c not in new_df.columns:
        new_df[c] = pd.NA

# Eski veri iÃ§inden sadece bugÃ¼ne aitleri tut (baÅŸka gÃ¼n kalmasÄ±n)
if not existing_df.empty:
    if "time" in existing_df.columns:
        existing_df["time"] = pd.to_datetime(existing_df["time"], errors="coerce", utc=True)
    # EÄŸitim ÅŸemasÄ±na oturt
    for c in ["tweet","comment","retweet","like","see_count","time",
              "AÃ§Ä±lÄ±ÅŸ FiyatÄ± (USD)","KapanÄ±ÅŸ FiyatÄ± (USD)","Fark (USD)","target"]:
        if c not in existing_df.columns:
            existing_df[c] = pd.NA

# TÃ¼m yeni satÄ±rlar iÃ§in "bugÃ¼nÃ¼n klasÃ¶rÃ¼ = bugÃ¼nÃ¼n gÃ¼nÃ¼" kuralÄ±
# (tweet eski tarihli de olsa bugÃ¼nÃ¼n datasÄ± sayÄ±yoruz)
# -> BTC de bugÃ¼nÃ¼n aÃ§Ä±lÄ±ÅŸ/kapanÄ±ÅŸÄ± olacak
new_df["_processing_day"] = TODAY

# 4) BTC fiyatÄ± â€” CoinGecko âœ Binance fallback âœ Ã¶nceki kapanÄ±ÅŸ
def get_btc_ohlc_for_day(day_str: str, prev_close=None):
    try:
        day = datetime.strptime(day_str, "%Y-%m-%d").date()
        start_ts = int(datetime.combine(day, datetime.min.time(), tzinfo=timezone.utc).timestamp())
        end_ts   = int(datetime.combine(day + timedelta(days=1), datetime.min.time(), tzinfo=timezone.utc).timestamp())

        # 4.1 CoinGecko
        cg = f"https://api.coingecko.com/api/v3/coins/bitcoin/market_chart/range?vs_currency=usd&from={start_ts}&to={end_ts}"
        r = requests.get(cg, timeout=15)
        if r.status_code == 200:
            prices = r.json().get("prices", [])
            if prices:
                prices.sort(key=lambda x: x[0])
                o, c = prices[0][1], prices[-1][1]
                return o, c

        # 4.2 Binance fallback
        b = f"https://api.binance.com/api/v3/klines?symbol=BTCUSDT&interval=1d&startTime={start_ts*1000}&endTime={end_ts*1000}"
        rr = requests.get(b, timeout=10)
        if rr.status_code == 200 and len(rr.json()) > 0:
            o, c = float(rr.json()[0][1]), float(rr.json()[0][4])
            return o, c

        print(f"âš ï¸ BTC fiyatÄ± alÄ±namadÄ± ({day_str})")
        if prev_close is not None:
            # open=close=prev_close ile doldur
            return prev_close, prev_close
        return None, None
    except Exception as e:
        print(f"âš ï¸ BTC hata ({day_str}): {e}")
        if prev_close is not None:
            return prev_close, prev_close
        return None, None

# BugÃ¼n iÃ§in OHLC Ã§ek (tek gÃ¼n)
prev_close_known = None
o, c = get_btc_ohlc_for_day(TODAY, prev_close=prev_close_known)
open_usd, close_usd = o, c
diff_usd = (close_usd - open_usd) if (open_usd is not None and close_usd is not None) else None

# 5) EÄŸitim ÅŸemasÄ±na uygun kolonlarÄ± kur & deÄŸerle
def to_training_schema(df: pd.DataFrame) -> pd.DataFrame:
    out = pd.DataFrame()
    out["tweet"]  = df["tweet"].astype(str)
    out["comment"] = pd.to_numeric(df["comment"], errors="coerce").fillna(0).astype(int)
    out["retweet"] = pd.to_numeric(df["retweet"], errors="coerce").fillna(0).astype(int)
    out["like"]    = pd.to_numeric(df["like"], errors="coerce").fillna(0).astype(int)
    out["see_count"] = pd.to_numeric(df["see_count"], errors="coerce").fillna(0).astype(int)
    out["time"]   = pd.to_datetime(df["time"], errors="coerce", utc=True)

    # BTC kolonlarÄ±nÄ± sabit adlarla doldur
    out["AÃ§Ä±lÄ±ÅŸ FiyatÄ± (USD)"]  = open_usd
    out["KapanÄ±ÅŸ FiyatÄ± (USD)"] = close_usd
    out["Fark (USD)"]           = diff_usd

    # target bilinmiyor -> boÅŸ
    out["target"] = pd.NA
    return out

existing_t = to_training_schema(existing_df) if not existing_df.empty else pd.DataFrame(columns=[
    "tweet","comment","retweet","like","see_count","time",
    "AÃ§Ä±lÄ±ÅŸ FiyatÄ± (USD)","KapanÄ±ÅŸ FiyatÄ± (USD)","Fark (USD)","target"
])
new_t = to_training_schema(new_df)

# Sadece bugÃ¼nÃ¼n verisini barÄ±ndÄ±r (eski gÃ¼nler bu dosyada tutulmasÄ±n)
# Not: existing tarafÄ±nda da olsa, bugÃ¼ne ait olmayanlarÄ± at
def is_today(ts):
    try:
        return (pd.Timestamp(ts).tz_convert("UTC").strftime("%Y-%m-%d") == TODAY)
    except Exception:
        return True  # zaman yoksa bugÃ¼ne say

existing_t = existing_t[existing_t["time"].apply(is_today)] if not existing_t.empty else existing_t

combined = pd.concat([existing_t, new_t], ignore_index=True)
combined.drop_duplicates(subset=["tweet","time"], inplace=True)

# 6) Kaydet & YÃ¼kle
os.makedirs(f"/tmp/{TODAY}", exist_ok=True)
out_path = f"/tmp/{TODAY}/pegos_final_dataset.csv"
combined.to_csv(out_path, index=False, encoding="utf-8")
print(f"ğŸ’¾ Kaydedildi: {out_path} ({len(combined)} satÄ±r)")

upload_file(
    path_or_fileobj=out_path,
    path_in_repo=f"data/{TODAY}/pegos_final_dataset.csv",
    repo_id=HF_DATASET_REPO,
    repo_type="dataset",
    token=HF_TOKEN,
    commit_message=f"Append merged dataset for {TODAY} (today-only, stable schema)"
)
print("ğŸš€ Dataset Hugging Faceâ€™e baÅŸarÄ±yla yÃ¼klendi.")
