# =====================================================
# Pegos Dataset Builder (Append + Daily Folder + Fallback + Stable)
# =====================================================
import os
import time
import pandas as pd
import requests
from datetime import datetime, timezone
from huggingface_hub import HfApi, hf_hub_download, upload_file

# === ENV AYARLARI ===
HF_TOKEN = os.getenv("HF_TOKEN")
HF_DATASET_REPO = os.getenv("HF_DATASET_REPO")
api = HfApi(token=HF_TOKEN)

TODAY = datetime.utcnow().strftime("%Y-%m-%d")
print(f"ğŸ“‚ GÃ¼nlÃ¼k klasÃ¶r: {TODAY}")

# =====================================================
# 1ï¸âƒ£ Mevcut gÃ¼nÃ¼n final dosyasÄ± varsa indir
# =====================================================
merged_hf = f"data/{TODAY}/pegos_final_dataset.csv"
existing_df = pd.DataFrame()
try:
    print(f"ğŸ“¥ HF Ã¼zerinde {merged_hf} aranÄ±yor...")
    local_existing = hf_hub_download(
        repo_id=HF_DATASET_REPO,
        filename=merged_hf,
        repo_type="dataset",
        token=HF_TOKEN
    )
    existing_df = pd.read_csv(local_existing)
    print(f"ğŸ” Mevcut veri bulundu: {len(existing_df)} satÄ±r")
except Exception:
    print("â„¹ï¸ Mevcut gÃ¼nlÃ¼k dataset yok, yeni oluÅŸturulacak.")

# =====================================================
# 2ï¸âƒ£ Yeni tweet dosyasÄ±nÄ± bul (Ã¶nce latest.csv, yoksa arÅŸiv)
# =====================================================
new_df = pd.DataFrame()
candidate_files = [
    f"data/{TODAY}/latest.csv",
    f"data/{TODAY}/blockchain_tweets_{TODAY}.csv"
]

found_path = None
for file in candidate_files:
    try:
        print(f"ğŸ“¥ Kontrol ediliyor: {file}")
        found_path = hf_hub_download(
            repo_id=HF_DATASET_REPO,
            filename=file,
            repo_type="dataset",
            token=HF_TOKEN
        )
        print(f"âœ… Dosya bulundu: {file}")
        break
    except Exception:
        continue

if not found_path:
    raise RuntimeError("âŒ HF Ã¼zerinde tweet CSV bulunamadÄ± (ne latest ne arÅŸiv).")

new_df = pd.read_csv(found_path)
if new_df.empty:
    print("âš ï¸ Yeni tweet verisi boÅŸ geldi, pipeline devam ediyor...")

# normalize & gÃ¼n kolonu
new_df["time"] = pd.to_datetime(new_df.get("time"), errors="coerce", utc=True)
new_df["day"] = new_df["time"].dt.strftime("%Y-%m-%d")

# =====================================================
# 3ï¸âƒ£ Append + unique
# =====================================================
combined = pd.concat([existing_df, new_df], ignore_index=True)
combined.drop_duplicates(subset=["tweet", "time"], inplace=True)
print(f"ğŸ“Š BirleÅŸtirilmiÅŸ toplam: {len(combined)} satÄ±r")

# =====================================================
# 4ï¸âƒ£ BTC fiyatlarÄ±nÄ± al (her gÃ¼n iÃ§in open/close)
# =====================================================
def get_btc_prices(day_str: str):
    try:
        day = datetime.strptime(day_str, "%Y-%m-%d").date()
        base = "https://api.coingecko.com/api/v3/coins/bitcoin/market_chart/range"
        start = int(datetime.combine(day, datetime.min.time(), tzinfo=timezone.utc).timestamp())
        end = int(datetime.combine(day, datetime.max.time(), tzinfo=timezone.utc).timestamp())
        url = f"{base}?vs_currency=usd&from={start}&to={end}"
        r = requests.get(url, timeout=15)
        if r.status_code != 200:
            return None, None
        data = r.json().get("prices", [])
        if not data:
            return None, None
        data.sort(key=lambda x: x[0])
        return data[0][1], data[-1][1]
    except Exception:
        return None, None

# tÃ¼r karÄ±ÅŸÄ±klÄ±ÄŸÄ±nÄ± Ã¶nlemek iÃ§in day -> str
combined["day"] = combined["day"].astype(str)
unique_days = sorted(combined["day"].dropna().unique())

btc_rows = []
for day in unique_days:
    op, cl = get_btc_prices(day)
    btc_rows.append({"day": day, "open": op, "close": cl})
    time.sleep(0.3)

btc_df = pd.DataFrame(btc_rows)
btc_df["diff"] = btc_df["close"] - btc_df["open"]
btc_df["direction"] = (btc_df["diff"] > 0).astype(int)

final_df = combined.merge(btc_df, on="day", how="left")

# =====================================================
# 5ï¸âƒ£ Kaydet & Hugging Face'e yÃ¼kle
# =====================================================
os.makedirs(f"/tmp/{TODAY}", exist_ok=True)
out_path = f"/tmp/{TODAY}/pegos_final_dataset.csv"
final_df.to_csv(out_path, index=False)
print(f"ğŸ’¾ Kaydedildi: {out_path} ({len(final_df)} satÄ±r)")

try:
    upload_file(
        path_or_fileobj=out_path,
        path_in_repo=f"data/{TODAY}/pegos_final_dataset.csv",
        repo_id=HF_DATASET_REPO,
        repo_type="dataset",
        token=HF_TOKEN,
        commit_message=f"Append merged dataset for {TODAY}"
    )
    print("ğŸš€ GÃ¼nlÃ¼k dataset Hugging Faceâ€™e baÅŸarÄ±yla yÃ¼klendi.")
except Exception as e:
    print(f"âš ï¸ Upload sÄ±rasÄ±nda hata oluÅŸtu: {e}")
