{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# Pegos Twitter Scraper (Enhanced for Accurate Counts)\n",
    "# =====================================================\n",
    "import os, time, random, traceback\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "def get_tweet_counts(art):\n",
    "    \"\"\"Yeni Twitter DOM'una g√∂re etkile≈üim sayƒ±larƒ± √ßeker.\"\"\"\n",
    "    counts = {\"comment\": 0, \"retweet\": 0, \"like\": 0, \"see_count\": 0}\n",
    "\n",
    "    for label, key in [\n",
    "        (\"reply\", \"comment\"),\n",
    "        (\"retweet\", \"retweet\"),\n",
    "        (\"like\", \"like\"),\n",
    "        (\"view\", \"see_count\"),\n",
    "    ]:\n",
    "        try:\n",
    "            tag = art.find(attrs={\"data-testid\": label})\n",
    "            if not tag:\n",
    "                continue\n",
    "            val = tag.get_text(strip=True)\n",
    "            if not val:\n",
    "                continue\n",
    "            if val.endswith(\"B\"):\n",
    "                val = float(val[:-1]) * 1000\n",
    "            elif val.endswith(\"Mn\") or val.endswith(\"M\"):\n",
    "                val = float(val[:-2]) * 1_000_000\n",
    "            elif val.isdigit():\n",
    "                val = float(val)\n",
    "            else:\n",
    "                val = 0\n",
    "            counts[key] = int(val)\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# ENV deƒüi≈ükenleri (GitHub Secrets)\n",
    "# --------------------------\n",
    "AUTH_TOKEN = os.getenv(\"AUTH_TOKEN\")\n",
    "CT0 = os.getenv(\"CT0\")\n",
    "OUT_PATH = \"/tmp/pegos_output.csv\"\n",
    "\n",
    "if not AUTH_TOKEN or not CT0:\n",
    "    raise RuntimeError(\"AUTH_TOKEN veya CT0 tanƒ±mlƒ± deƒüil (GitHub Secrets kƒ±smƒ±na ekle).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Chrome ba≈ülat (headless)\n",
    "# --------------------------\n",
    "opts = Options()\n",
    "opts.add_argument(\"--headless=new\")\n",
    "opts.add_argument(\"--no-sandbox\")\n",
    "opts.add_argument(\"--disable-dev-shm-usage\")\n",
    "opts.add_argument(\"--disable-gpu\")\n",
    "opts.add_argument(\"--window-size=1920,1080\")\n",
    "opts.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "opts.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "opts.add_experimental_option(\"useAutomationExtension\", False)\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Login with cookies\n",
    "# --------------------------\n",
    "driver.get(\"https://x.com\")\n",
    "time.sleep(3)\n",
    "driver.add_cookie({\"name\": \"auth_token\", \"value\": AUTH_TOKEN, \"domain\": \".x.com\"})\n",
    "driver.add_cookie({\"name\": \"ct0\", \"value\": CT0, \"domain\": \".x.com\"})\n",
    "driver.refresh()\n",
    "time.sleep(4)\n",
    "print(\"‚úÖ Cookies set, current URL:\", driver.current_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Tweet scraping (improved)\n",
    "# --------------------------\n",
    "KEYWORDS = ['blockchain', 'cryptocurrency', 'bitcoin', 'ethereum']\n",
    "tweetArr = []\n",
    "\n",
    "for kw in KEYWORDS:\n",
    "    print(f\"üîé Searching for: {kw}\")\n",
    "    driver.get(f\"https://x.com/search?q={kw}&src=typed_query&f=live\")\n",
    "    time.sleep(5)\n",
    "\n",
    "    for scroll_round in range(35):\n",
    "        driver.execute_script(\"window.scrollBy(0, 1200);\")\n",
    "        time.sleep(random.uniform(1.5, 2.5))  # JS y√ºklenmesi i√ßin bekleme\n",
    "        driver.execute_script(\"window.scrollBy(0, -200);\")  # Lazy-load d√ºzeltme\n",
    "\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "        articles = soup.find_all(\"article\") or []\n",
    "\n",
    "        for art in articles:\n",
    "            try:\n",
    "                tag = art.find(attrs={\"data-testid\": \"tweetText\"})\n",
    "                if not tag:\n",
    "                    continue\n",
    "\n",
    "                text = tag.get_text(\" \", strip=True)\n",
    "                time_tag = art.find(\"time\")\n",
    "                time_str = time_tag[\"datetime\"] if time_tag else None\n",
    "\n",
    "                counts = get_tweet_counts(art)\n",
    "\n",
    "                tweetArr.append({\n",
    "                    \"keyword\": kw,\n",
    "                    \"tweet\": text,\n",
    "                    \"time\": time_str,\n",
    "                    **counts\n",
    "                })\n",
    "\n",
    "            except Exception as e:\n",
    "                print(\"‚ö†Ô∏è Parse error:\", e)\n",
    "\n",
    "    print(f\"‚úÖ Finished {kw}: total tweets so far {len(tweetArr)}\")\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Save to CSV\n",
    "# --------------------------\n",
    "df = pd.DataFrame(tweetArr)\n",
    "if df.empty:\n",
    "    print(\"‚ö†Ô∏è No tweets collected.\")\n",
    "else:\n",
    "    df.drop_duplicates(subset=['tweet', 'time'], inplace=True)\n",
    "    df.to_csv(OUT_PATH, index=False)\n",
    "    print(f\"üíæ Saved to {OUT_PATH}, total {len(df)} rows.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
